{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libs",
   "id": "4065274cb3e8cff7"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T03:57:47.449313Z",
     "start_time": "2024-11-20T03:57:43.959598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os \n",
    "import torch \n",
    "import einops\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.nn import Linear\n",
    "from triton.ops import attention\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Data",
   "id": "c316841afaba43cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:57:49.694110Z",
     "start_time": "2024-11-20T03:57:47.653520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = OGB_MAG(root='./data', preprocess='metapath2vec')\n",
    "data = dataset[0]\n",
    "\n",
    "# normalize data\n",
    "data = T.ToUndirected()(data)\n",
    "data = T.AddSelfLoops()(data)\n",
    "data = T.NormalizeFeatures()(data)"
   ],
   "id": "5410ecbde62dc735",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:41:45.979445Z",
     "start_time": "2024-11-20T03:41:45.973297Z"
    }
   },
   "cell_type": "code",
   "source": "print(data)",
   "id": "4d7f6f20903caa77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  paper={\n",
      "    x=[736389, 128],\n",
      "    year=[736389],\n",
      "    y=[736389],\n",
      "    train_mask=[736389],\n",
      "    val_mask=[736389],\n",
      "    test_mask=[736389],\n",
      "  },\n",
      "  author={ x=[1134649, 128] },\n",
      "  institution={ x=[8740, 128] },\n",
      "  field_of_study={ x=[59965, 128] },\n",
      "  (author, affiliated_with, institution)={ edge_index=[2, 1043998] },\n",
      "  (author, writes, paper)={ edge_index=[2, 7145660] },\n",
      "  (paper, cites, paper)={ edge_index=[2, 11529061] },\n",
      "  (paper, has_topic, field_of_study)={ edge_index=[2, 7505078] },\n",
      "  (institution, rev_affiliated_with, author)={ edge_index=[2, 1043998] },\n",
      "  (paper, rev_writes, author)={ edge_index=[2, 7145660] },\n",
      "  (field_of_study, rev_has_topic, paper)={ edge_index=[2, 7505078] }\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:41:46.160870Z",
     "start_time": "2024-11-20T03:41:46.154844Z"
    }
   },
   "cell_type": "code",
   "source": "data.metadata()",
   "id": "1346cf4674a2f35b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['paper', 'author', 'institution', 'field_of_study'],\n",
       " [('author', 'affiliated_with', 'institution'),\n",
       "  ('author', 'writes', 'paper'),\n",
       "  ('paper', 'cites', 'paper'),\n",
       "  ('paper', 'has_topic', 'field_of_study'),\n",
       "  ('institution', 'rev_affiliated_with', 'author'),\n",
       "  ('paper', 'rev_writes', 'author'),\n",
       "  ('field_of_study', 'rev_has_topic', 'paper')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Design Model Architecture",
   "id": "f3494396cd8c5a9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:41:46.390160Z",
     "start_time": "2024-11-20T03:41:46.365034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HeteroGATLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 metadata,\n",
    "                 n_heads=4,\n",
    "                 dropout=0.5,\n",
    "                 device=None):\n",
    "\n",
    "        \"\"\"\n",
    "        Custom GAT Layer for heterogeneous data.\n",
    "\n",
    "        Args:\n",
    "        - in_features: input dimensions for each node type, \n",
    "                       assuming that each not type has the same dimension\n",
    "        - out_features: Output dimension per head attention.\n",
    "        - metadata: Tuple (node_types, edge_types) for the heterogeneous graph.\n",
    "        - n_heads: Number of attention heads.\n",
    "        - dropout: Dropout rate for attention coefficients.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.node_types, self.edge_types = metadata\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Learnable weight matrices for each edge type\n",
    "        self.edge_transforms = nn.ParameterDict({\n",
    "            repr(edge_type): nn.Parameter(torch.randn(size=(in_features, n_heads, out_features), device=device))\n",
    "            for edge_type in self.edge_types\n",
    "        })\n",
    "        for edge_type in self.edge_transforms:\n",
    "            nn.init.xavier_normal_(self.edge_transforms[edge_type])\n",
    "\n",
    "        # Learnable weight matrices for attention mechanism for each edge type\n",
    "        self.attention_weights = nn.ParameterDict({\n",
    "            repr(edge_type): nn.Parameter(torch.randn(size=(n_heads, 2 * out_features, 1), device=device))\n",
    "            for edge_type in self.edge_types\n",
    "        })\n",
    "        for edge_type in self.attention_weights:\n",
    "            nn.init.xavier_normal_(self.attention_weights[edge_type])\n",
    "\n",
    "        # Learnable weight matrices for each node types \n",
    "        self.node_transforms = nn.ModuleDict({\n",
    "            node_type: Linear(in_channels=-1, out_channels=out_features).to(device)\n",
    "            for node_type in self.node_types\n",
    "        })\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def _get_attention_scores(self, h_src, h_dst, edge_index, edge_type):\n",
    "        \"\"\"\n",
    "        Compute attention scores of source nodes for each destination nodes\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate attention mechanism for message passing \n",
    "        # Target: attention scores: [n_heads, num_src, num_dst] \n",
    "        # -> dst nodes receive message from src nodes\n",
    "\n",
    "        # step 1. broadcast src nodes and dst nodes and concat them to create attention features:\n",
    "        num_dst = h_dst.size(0)\n",
    "        num_src = h_src.size(0)\n",
    "                \n",
    "        h_src_repeat = h_src.repeat(1, num_dst, 1).view(num_src * num_dst, -1,\n",
    "                                                        h_src.size(-1))                                 # [num_src*num_dst, n_heads, out_dim]\n",
    "\n",
    "        h_dst_repeat = h_dst.repeat(num_src, 1, 1)                                                      # [num_src*num_dst, n_heads, out_dim]\n",
    "\n",
    "        a_input = (torch.cat([h_src_repeat, h_dst_repeat], dim=-1)                                      # [num_dst, n_heads, num_src, 2*out_dim]\n",
    "                   .view(num_dst, -1, num_src, h_src.size(-1) * 2))\n",
    "\n",
    "        # step 2. calculate attention scores base on edge_type\n",
    "\n",
    "        attention_scores = (self.leaky_relu(torch.matmul(a_input,                                       # [num_dst, n_heads, num_src]\n",
    "                                                         self.attention_weights[repr(edge_type)]))\n",
    "                            .squeeze(-1))\n",
    "\n",
    "        # step 3. mask the neighbors using adjacency matrix \n",
    "\n",
    "        adjacency_matrix = torch.zeros((h_dst.size(0), h_src.size(0)),                                  # [num_dst, num_src] \n",
    "                                       device=device)\n",
    "        \n",
    "        adjacency_matrix[edge_index[1], edge_index[0]] = 1\n",
    "        adjacency_matrix = einops.repeat(adjacency_matrix, \"m n -> m k n\",\n",
    "                                         k=self.n_heads)                                                # [num_dst, n_heads, num_src]\n",
    "        \n",
    "        attention_scores = attention_scores.masked_fill(adjacency_matrix == 0, float('-inf'))\n",
    "        \n",
    "        # step 4. compute softmax on the source nodes dimension \n",
    "        attention_scores = F.softmax(attention_scores, dim=-1)                                          # [num_dst, n_heads, num_src] \n",
    "           \n",
    "        # print(attention_scores.shape)\n",
    "        # print(torch.sum(attention_scores, dim=-1)[0])\n",
    "    \n",
    "        return attention_scores\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "\n",
    "        out_dict = {}\n",
    "        \n",
    "        # Iterate over edge types\n",
    "        for edge_type, edge_index in edge_index_dict.items():\n",
    "            if edge_index.size()[1] == 0:\n",
    "                continue \n",
    "            \n",
    "            src_type, _, dst_type = edge_type\n",
    "            if src_type not in x_dict or dst_type not in x_dict:\n",
    "                continue \n",
    "            \n",
    "            # step 1. apply linear transformation to src and dst features base on edge type \n",
    "            \n",
    "            if isinstance(x_dict[src_type], list):\n",
    "                print(src_type, edge_type)\n",
    "            \n",
    "            h_src = torch.matmul(x_dict[src_type],  # [n_heads, num_src, out_dim]\n",
    "                                 self.edge_transforms[repr(edge_type)].permute(1, 0, 2))\n",
    "            # print('h_src', h_src[0][:10])\n",
    "            h_src = h_src.permute(1, 0, 2)                                                              # [num_src, n_heads, out_dim]\n",
    "\n",
    "            h_dst = torch.matmul(x_dict[dst_type],                                                      # [n_heads, num_dst, out_dim]\n",
    "                                 self.edge_transforms[repr(edge_type)].permute(1, 0, 2))\n",
    "            h_dst = h_dst.permute(1, 0, 2)                                                              # [num_dst, n_heads, out_dim]\n",
    "\n",
    "            h_src = F.dropout(h_src, self.dropout, training=self.training)\n",
    "            h_dst = F.dropout(h_dst, self.dropout, training=self.training)\n",
    "            \n",
    "            # step 2. compute message passing using attention mechanism \n",
    "            \n",
    "            attention_scores = self._get_attention_scores(h_src, h_dst, edge_index, edge_type)\n",
    "\n",
    "            # step 3. update dst node embeddings base on the message from src nodes \n",
    "            # step 3.a compute dst node embeddings base on attention scores\n",
    "            updated_h_dst = torch.matmul(attention_scores.permute(1, 0, 2),\n",
    "                                             h_src.permute(1, 0, 2))                                    # [n_heads, num_dst, out_dim]             \n",
    "                        \n",
    "            \n",
    "            # step 3.b aggregate the features from multi head attentions. \n",
    "            updated_h_dst = torch.mean(updated_h_dst, dim=0).squeeze(0)                                  # [num_dst, out_dim]  \n",
    "            # print(edge_type)\n",
    "            # print('updated_h_dst', updated_h_dst.shape)\n",
    "            # print(updated_h_dst)\n",
    "            \n",
    "            # step 3.c check nan in h_dst, nan means isolated nodes and replace the nan row by ....\n",
    "            nan_mask = torch.isnan(updated_h_dst).all(dim=1)                                            # [num_dist,]\n",
    "            # print(h_dst.shape)\n",
    "            # h_dst = torch.sum(h_dst, dim=1)                                                           # [num_dist, out_dim]\n",
    "            # print('h_dst', h_dst.shape)\n",
    "            updated_h_dst[nan_mask] = torch.zeros_like(updated_h_dst)[nan_mask]\n",
    "            # print(updated_h_dst)\n",
    "\n",
    "            # step 4. append to the output for this node type. \n",
    "            # be aware that one edge type might be involved in multiple types of edge \n",
    "            if dst_type not in out_dict:\n",
    "                out_dict[dst_type] = [updated_h_dst]\n",
    "            else:\n",
    "                out_dict[dst_type].append(updated_h_dst)\n",
    "\n",
    "        # step 5. combine all the edge type per node type and transform one more time. \n",
    "        for node_type in out_dict:            \n",
    "            # aggregate by concatenating/summing  \n",
    "            # out_dict[node_type] = torch.cat(out_dict[node_type], dim=1)\n",
    "            out_dict[node_type] = torch.stack(out_dict[node_type], dim=1)\n",
    "            # print(out_dict[node_type].shape)\n",
    "            out_dict[node_type] = torch.sum(out_dict[node_type], dim=1)\n",
    "            # print(out_dict[node_type].shape)\n",
    "            out_dict[node_type] = self.node_transforms[node_type](out_dict[node_type])\n",
    "\n",
    "        return out_dict                  "
   ],
   "id": "8edec9b896cd8fb1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:41:46.557133Z",
     "start_time": "2024-11-20T03:41:46.551055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HeteroGAT(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, num_classes, metadata, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gat_layer1 = HeteroGATLayer(in_features=in_features,\n",
    "                                         out_features=num_classes,\n",
    "                                         n_heads=1,\n",
    "                                         dropout=0.5,\n",
    "                                         metadata=metadata,\n",
    "                                         device=device)\n",
    "        \n",
    "        self.gat_layer2 = HeteroGATLayer(in_features=hidden_dim,\n",
    "                                         out_features=num_classes,\n",
    "                                         n_heads=1,\n",
    "                                         dropout=0.5,\n",
    "                                         metadata=metadata,\n",
    "                                         device=device)\n",
    "        \n",
    "        node_types, _ = metadata\n",
    "        self.fc = {\n",
    "            node_type: Linear(-1, hidden_dim).to(device)\n",
    "            for node_type in node_types\n",
    "        }\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        \n",
    "        out_dict = self.gat_layer1(x_dict, edge_index_dict)        \n",
    "        \n",
    "        for node_type in out_dict:\n",
    "            # if not isinstance(out_dict[node_type], list):\n",
    "            out_dict[node_type] = out_dict[node_type] + self.fc[node_type](out_dict[node_type])\n",
    "            out_dict[node_type] = F.elu(out_dict[node_type])\n",
    "        \n",
    "        out_dict = self.gat_layer2(out_dict, edge_index_dict)\n",
    "        \n",
    "        return out_dict \n",
    "        "
   ],
   "id": "d321e9f0e05a1ff6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:05:42.852609Z",
     "start_time": "2024-11-20T04:05:41.317446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = NeighborLoader(data,\n",
    "                              num_neighbors=[30,30],\n",
    "                              batch_size=128,\n",
    "                              input_nodes=('paper', data['paper'].train_mask))"
   ],
   "id": "42b4bba68983c5e7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:50:04.844012Z",
     "start_time": "2024-11-20T03:41:48.289530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "in_features = 128\n",
    "hidden_dim = 64\n",
    "num_classes = dataset.num_classes\n",
    "metadata = data.metadata()\n",
    "\n",
    "hetero_gat = HeteroGAT(in_features=in_features,\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       num_classes=num_classes,\n",
    "                       metadata=metadata,\n",
    "                       device=device).to(device)\n",
    "\n",
    "optim = torch.optim.Adam(hetero_gat.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_loss = []\n",
    "    with tqdm(train_loader, desc=f'Train. Epoch {epoch}', unit='batch') as t:\n",
    "        for batch in t:\n",
    "            optim.zero_grad()\n",
    "            batch = batch.to(device)\n",
    "            batch_size = batch['paper']['batch_size']\n",
    "        \n",
    "            output = hetero_gat(batch.x_dict, batch.edge_index_dict)\n",
    "            loss = F.cross_entropy(output['paper'][:batch_size],\n",
    "                                   batch['paper']['y'][:batch_size])\n",
    "            \n",
    "            epoch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            t.set_postfix(loss=sum(epoch_loss)/len(epoch_loss))\n"
   ],
   "id": "b9ed669f3ca11358",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train. Epoch 0: 100%|██████████| 4919/4919 [07:46<00:00, 10.54batch/s, loss=5.02]\n",
      "Train. Epoch 1:   6%|▌         | 280/4919 [00:29<08:02,  9.61batch/s, loss=5]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 19\u001B[0m\n\u001B[1;32m     17\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(train_loader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain. Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m t:\n\u001B[0;32m---> 19\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m t:\n\u001B[1;32m     20\u001B[0m         optim\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     21\u001B[0m         batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m/HDD/.conda/envs/nld-pyg/lib/python3.9/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m/HDD/.conda/envs/nld-pyg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/HDD/.conda/envs/nld-pyg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/HDD/.conda/envs/nld-pyg/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/HDD/.conda/envs/nld-pyg/lib/python3.9/site-packages/torch_geometric/loader/node_loader.py:150\u001B[0m, in \u001B[0;36mNodeLoader.collate_fn\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    147\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_sampler\u001B[38;5;241m.\u001B[39msample_from_nodes(input_data)\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilter_per_worker:  \u001B[38;5;66;03m# Execute `filter_fn` in the worker process\u001B[39;00m\n\u001B[0;32m--> 150\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilter_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m/HDD/.conda/envs/nld-pyg/lib/python3.9/site-packages/torch_geometric/loader/node_loader.py:211\u001B[0m, in \u001B[0;36mNodeLoader.filter_fn\u001B[0;34m(self, out)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, HeteroSamplerOutput):\n\u001B[1;32m    210\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata, HeteroData):\n\u001B[0;32m--> 211\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43mfilter_hetero_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m#\u001B[39;49;00m\n\u001B[1;32m    212\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_sampler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_permutation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Tuple[FeatureStore, GraphStore]\u001B[39;00m\n\u001B[1;32m    216\u001B[0m \n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Hack to detect whether we are in a distributed setting.\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_sampler\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m\n\u001B[1;32m    219\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDistNeighborSampler\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m/HDD/.conda/envs/nld-pyg/lib/python3.9/site-packages/torch_geometric/loader/utils.py:184\u001B[0m, in \u001B[0;36mfilter_hetero_data\u001B[0;34m(data, node_dict, row_dict, col_dict, edge_dict, perm_dict)\u001B[0m\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m node_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m node_dict:\n\u001B[1;32m    182\u001B[0m         node_dict[node_type] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(\u001B[38;5;241m0\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m--> 184\u001B[0m     \u001B[43mfilter_node_store_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnode_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnode_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mnode_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnode_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m edge_type \u001B[38;5;129;01min\u001B[39;00m out\u001B[38;5;241m.\u001B[39medge_types:\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;66;03m# Handle the case of disconneted graph sampling:\u001B[39;00m\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m edge_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m row_dict:\n",
      "File \u001B[0;32m/HDD/.conda/envs/nld-pyg/lib/python3.9/site-packages/torch_geometric/loader/utils.py:99\u001B[0m, in \u001B[0;36mfilter_node_store_\u001B[0;34m(store, out_store, index)\u001B[0m\n\u001B[1;32m     97\u001B[0m     index \u001B[38;5;241m=\u001B[39m index\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[1;32m     98\u001B[0m dim \u001B[38;5;241m=\u001B[39m store\u001B[38;5;241m.\u001B[39m_parent()\u001B[38;5;241m.\u001B[39m__cat_dim__(key, value, store)\n\u001B[0;32m---> 99\u001B[0m out_store[key] \u001B[38;5;241m=\u001B[39m \u001B[43mindex_select\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/HDD/.conda/envs/nld-pyg/lib/python3.9/site-packages/torch_geometric/loader/utils.py:73\u001B[0m, in \u001B[0;36mindex_select\u001B[0;34m(value, index, dim)\u001B[0m\n\u001B[1;32m     70\u001B[0m             storage \u001B[38;5;241m=\u001B[39m value\u001B[38;5;241m.\u001B[39mstorage()\u001B[38;5;241m.\u001B[39m_new_shared(numel)\n\u001B[1;32m     71\u001B[0m         out \u001B[38;5;241m=\u001B[39m value\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mview(size)\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex_select\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, TensorFrame):\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m dim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6ad68f0fcc05f848"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
