{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libs",
   "id": "4065274cb3e8cff7"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import os \n",
    "import torch \n",
    "import einops\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from mkl_random import geometric\n",
    "\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.nn import Linear\n",
    "from triton.ops import attention\n",
    "import torch_geometric\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Data",
   "id": "c316841afaba43cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = OGB_MAG(root='./data', preprocess='metapath2vec')\n",
    "data = dataset[0]\n",
    "\n",
    "# normalize data\n",
    "data = T.ToUndirected()(data)\n",
    "data = T.AddSelfLoops()(data)\n",
    "data = T.NormalizeFeatures()(data)"
   ],
   "id": "5410ecbde62dc735",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(data)",
   "id": "4d7f6f20903caa77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.metadata()",
   "id": "1346cf4674a2f35b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Design Model Architecture",
   "id": "f3494396cd8c5a9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T07:35:12.617825Z",
     "start_time": "2024-11-20T07:35:12.588779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HeteroGATLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 metadata,\n",
    "                 n_heads=4,\n",
    "                 dropout=0.5,\n",
    "                 device=None):\n",
    "\n",
    "        \"\"\"\n",
    "        Custom GAT Layer for heterogeneous data.\n",
    "\n",
    "        Args:\n",
    "        - in_features: input dimensions for each node type, \n",
    "                       assuming that each not type has the same dimension\n",
    "        - out_features: Output dimension per head attention.\n",
    "        - metadata: Tuple (node_types, edge_types) for the heterogeneous graph.\n",
    "        - n_heads: Number of attention heads.\n",
    "        - dropout: Dropout rate for attention coefficients.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.node_types, self.edge_types = metadata\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Learnable weight matrices for each edge type\n",
    "        self.edge_transforms = nn.ParameterDict({\n",
    "            repr(edge_type): nn.Parameter(torch.randn(size=(in_features, n_heads, out_features), device=device))\n",
    "            for edge_type in self.edge_types\n",
    "        })\n",
    "        for edge_type in self.edge_transforms:\n",
    "            nn.init.xavier_normal_(self.edge_transforms[edge_type])\n",
    "\n",
    "        # Learnable weight matrices for attention mechanism for each edge type\n",
    "        self.attention_weights = nn.ParameterDict({\n",
    "            repr(edge_type): nn.Parameter(torch.randn(size=(n_heads, 2 * out_features, 1), device=device))\n",
    "            for edge_type in self.edge_types\n",
    "        })\n",
    "        for edge_type in self.attention_weights:\n",
    "            nn.init.xavier_normal_(self.attention_weights[edge_type])\n",
    "\n",
    "        # Learnable weight matrices for each node types \n",
    "        self.node_transforms = nn.ModuleDict({\n",
    "            node_type: Linear(in_channels=-1, out_channels=out_features).to(device)\n",
    "            for node_type in self.node_types\n",
    "        })\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def _get_attention_scores(self, h_src, h_dst, edge_index, edge_type):\n",
    "        \"\"\"\n",
    "        Compute attention scores of source nodes for each destination nodes\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate attention mechanism for message passing -> dst nodes receive message from src nodes\n",
    "        # Target: attention scores: [n_heads, n_edge] \n",
    "        \n",
    "        src_edge, dst_edge = edge_index\n",
    "\n",
    "        src_features = h_src[src_edge]                                                      # [n_edge, n_heads, dim]\n",
    "        \n",
    "        # prepare input features for attention \n",
    "        a_input = torch.cat([h_src[src_edge], h_dst[dst_edge]], dim=-1)                     # [n_edge, n_heads, 2*dim]\n",
    "\n",
    "        # calculate attention scores base on edge_type weight matrix \n",
    "        attention_scores = torch.matmul(a_input.permute(1, 0, 2),                           # [num_edges, n_heads, 1]\n",
    "                                        self.attention_weights[repr(edge_type)])  \n",
    "        \n",
    "        attention_scores = self.leaky_relu(attention_scores).permute(1, 0, 2).squeeze(-1)   # [num_edges, n_heads]\n",
    "\n",
    "        # compute softmax by index cluster (softmax for each destination node) \n",
    "        attention_scores = torch_geometric.utils.softmax(attention_scores, index=dst_edge)  # [num_edges, n_heads]\n",
    "        \n",
    "        return attention_scores\n",
    "        \n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "        # Iterate over edge types\n",
    "        for edge_type, edge_index in edge_index_dict.items():\n",
    "            src_type, _, dst_type = edge_type\n",
    "            src_edge, dst_edge = edge_index\n",
    "        \n",
    "            if edge_index.size()[1] == 0 or src_type not in x_dict or dst_type not in x_dict:\n",
    "                continue\n",
    "\n",
    "            # step 1. apply linear transformation to src and dst features base on edge type \n",
    "\n",
    "            if isinstance(x_dict[src_type], list):\n",
    "                print(src_type, edge_type)\n",
    "            \n",
    "            h_src = torch.matmul(x_dict[src_type],                                          # [n_heads, num_src, out_dim]\n",
    "                                 self.edge_transforms[repr(edge_type)].permute(1, 0, 2))\n",
    "            h_src = h_src.permute(1, 0, 2)                                                  # [num_src, n_heads, out_dim]\n",
    "\n",
    "            h_dst = torch.matmul(x_dict[dst_type],                                          # [n_heads, num_dst, out_dim]\n",
    "                                 self.edge_transforms[repr(edge_type)].permute(1, 0, 2))\n",
    "            h_dst = h_dst.permute(1, 0, 2)                                                  # [num_dst, n_heads, out_dim]\n",
    "\n",
    "            h_src = F.dropout(h_src, self.dropout, training=self.training)\n",
    "            h_dst = F.dropout(h_dst, self.dropout, training=self.training)\n",
    "\n",
    "            # step 2. compute message passing using attention mechanism \n",
    "            src_features = h_src[src_edge]\n",
    "            attention_scores = self._get_attention_scores(h_src, \n",
    "                                                          h_dst, \n",
    "                                                          edge_index, \n",
    "                                                          edge_type)\n",
    "            \n",
    "            messages = torch.einsum('ij,ijl -> ijl', attention_scores, src_features)        # [num_edges, n_heads, dim]\n",
    "\n",
    "            \n",
    "            # step 3. aggregate message of neighbors by average messages \n",
    "            \n",
    "            aggregated_features = torch.zeros((h_dst.size(0), \n",
    "                                               self.n_heads, messages.size(-1)), device=self.device)\n",
    "            aggregated_features = aggregated_features.index_add_(0, dst_edge, messages)\n",
    "    \n",
    "            edge_count = torch.zeros((h_dst.size(0),), device=self.device)\n",
    "            edge_count = edge_count.index_add_(0, dst_edge, torch.ones_like(dst_edge, dtype=torch.float))\n",
    "            edge_count = edge_count.clamp(min=1)\n",
    "    \n",
    "            aggregated_features = aggregated_features / edge_count.view(-1, 1, 1)\n",
    "            \n",
    "            # aggregate multi-head attention\n",
    "            aggregated_features = torch.mean(aggregated_features, dim=1)  \n",
    "\n",
    "            # step 4. append to the output for this node type, be aware that one edge type might be involved in multiple types of edge \n",
    "            if dst_type not in out_dict:\n",
    "                out_dict[dst_type] = [aggregated_features]\n",
    "            else:\n",
    "                out_dict[dst_type].append(aggregated_features)\n",
    "\n",
    "        # step 5. combine all the edge type per node type and transform one more time. \n",
    "        for node_type in out_dict:\n",
    "            # aggregate by concatenating/sum/average\n",
    "            out_dict[node_type] = torch.cat(out_dict[node_type], dim=1)\n",
    "            # out_dict[node_type] = torch.stack(out_dict[node_type], dim=1)\n",
    "            # out_dict[node_type] = torch.sum(out_dict[node_type], dim=1)\n",
    "\n",
    "            out_dict[node_type] = self.node_transforms[node_type](out_dict[node_type])\n",
    "\n",
    "        return out_dict                  "
   ],
   "id": "8edec9b896cd8fb1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T07:35:12.933824Z",
     "start_time": "2024-11-20T07:35:12.926968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HeteroGAT(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_features, \n",
    "                 hidden_dim, \n",
    "                 num_classes, \n",
    "                 n_heads=4,\n",
    "                 metadata,\n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gat_layer1 = HeteroGATLayer(in_features=in_features,\n",
    "                                         out_features=hidden_dim,\n",
    "                                         n_heads=n_heads,\n",
    "                                         dropout=0.5,\n",
    "                                         metadata=metadata,\n",
    "                                         device=device)\n",
    "        \n",
    "        self.gat_layer2 = HeteroGATLayer(in_features=hidden_dim,\n",
    "                                         out_features=num_classes,\n",
    "                                         n_heads=n_heads,\n",
    "                                         dropout=0.5,\n",
    "                                         metadata=metadata,\n",
    "                                         device=device)\n",
    "        \n",
    "        node_types, _ = metadata\n",
    "        self.fc = {\n",
    "            node_type: Linear(-1, hidden_dim).to(device)\n",
    "            for node_type in node_types\n",
    "        }\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        \n",
    "        out_dict = self.gat_layer1(x_dict, edge_index_dict)        \n",
    "        \n",
    "        for node_type in out_dict:\n",
    "            out_dict[node_type] = out_dict[node_type] + self.fc[node_type](out_dict[node_type])\n",
    "            out_dict[node_type] = F.elu(out_dict[node_type])\n",
    "\n",
    "        out_dict = self.gat_layer2(out_dict, edge_index_dict)\n",
    "        \n",
    "        return out_dict \n",
    "        "
   ],
   "id": "d321e9f0e05a1ff6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T07:36:16.198006Z",
     "start_time": "2024-11-20T07:36:14.836428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = NeighborLoader(data,\n",
    "                              num_neighbors=[50,50],\n",
    "                              batch_size=32,\n",
    "                              input_nodes=('paper', data['paper'].train_mask))"
   ],
   "id": "42b4bba68983c5e7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-20T07:36:16.345242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "in_features = 128\n",
    "hidden_dim = 128\n",
    "num_classes = dataset.num_classes\n",
    "metadata = data.metadata()\n",
    "\n",
    "hetero_gat = HeteroGAT(in_features=in_features,\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       num_classes=num_classes,\n",
    "                       metadata=metadata,\n",
    "                       device=device).to(device)\n",
    "\n",
    "optim = torch.optim.Adam(hetero_gat.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(1):\n",
    "    epoch_loss = []\n",
    "    with tqdm(train_loader, desc=f'Train. Epoch {epoch}', unit='batch') as t:\n",
    "        for batch in t:\n",
    "            optim.zero_grad()\n",
    "            batch = batch.to(device)\n",
    "            batch_size = batch['paper']['batch_size']\n",
    "        \n",
    "            output = hetero_gat(batch.x_dict, batch.edge_index_dict)\n",
    "            loss = F.cross_entropy(output['paper'][:batch_size],\n",
    "                                   batch['paper']['y'][:batch_size])\n",
    "            \n",
    "            epoch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            t.set_postfix(loss=sum(epoch_loss)/len(epoch_loss))"
   ],
   "id": "b9ed669f3ca11358",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train. Epoch 0:  49%|████▉     | 9702/19675 [22:28<33:09,  5.01batch/s, loss=4.77]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_src = 10\n",
    "num_dst = 6\n",
    "num_edge = 8\n",
    "\n",
    "dim = 3 \n",
    "n_heads = 2\n",
    "\n",
    "src_nodes = torch.randn(num_src, n_heads, dim)\n",
    "dst_nodes = torch.randn(num_dst, n_heads, dim)\n",
    "\n",
    "Wa = nn.Parameter(torch.randn(n_heads, 2*dim, 1))\n",
    "\n"
   ],
   "id": "eb809074cccdbe0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "src_edge = torch.randint(0, num_src, (num_edge,))\n",
    "dst_edge = torch.randint(0, num_dst, (num_edge,))\n",
    "\n",
    "edge_index = torch.cat([src_edge.unsqueeze(0), dst_edge.unsqueeze(0)], dim=0)\n",
    "edge_index"
   ],
   "id": "104dd48a97fd4029",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate attention \n",
    "\n",
    "src_features = src_nodes[src_edge]\n",
    "dst_features = dst_nodes[dst_edge]\n"
   ],
   "id": "9fd4fcf3ba9ac54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(src_features.shape)\n",
    "print(dst_features.shape)"
   ],
   "id": "116bf1240439a5c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a_input = torch.cat([src_features, dst_features], dim=-1)\n",
    "a_input.shape"
   ],
   "id": "63881c67c4b03aa7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "attention_scores = torch.matmul(a_input.permute(1,0,2), Wa).squeeze(-1)  # [n_heads, num_edge]\n",
    "# calculate attention score base on dst edge cluster \n",
    "attention_scores = torch_geometric.utils.softmax(attention_scores, index=dst_edge, dim=-1)\n",
    "attention_scores.shape"
   ],
   "id": "9f229cbb367b3edb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "messages = torch.einsum('ij,jil->ijl', attention_scores, src_features).permute(1,0,2)\n",
    "print(messages.shape)\n",
    "\n",
    "aggregated_features = torch.zeros((num_dst, n_heads, dim))\n",
    "print(aggregated_features.shape)\n",
    "\n",
    "aggregated_features = aggregated_features.index_add_(0, dst_edge, messages)\n",
    "\n",
    "edge_count = torch.zeros((num_dst,))\n",
    "edge_count = edge_count.index_add_(0, dst_edge, torch.ones_like(dst_edge, dtype=torch.float))\n",
    "edge_count = edge_count.clamp(min=1)\n",
    "\n",
    "aggregated_features/edge_count.view(-1,1,1)"
   ],
   "id": "46728798483a76d1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
